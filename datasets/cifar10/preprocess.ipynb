{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "root = settings.DATA_HOME['cifar10']\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=root, train=True, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=root, train=False, download=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "((20000,),\n (4000,),\n (20000,),\n (4000,),\n array([0, 1, 2, 3]),\n array([0, 1, 2, 3]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = np.array([0, 1, 8, 9])\n",
    "all_train_data = []\n",
    "all_train_labels = []\n",
    "for PIL_image, label in train_dataset:\n",
    "    # image = np.transpose(PIL_image, (2, 0, 1))\n",
    "    if label in label_list:\n",
    "        all_train_data.append(PIL_image)\n",
    "        all_train_labels.append(np.where(label_list == label)[0][0])\n",
    "\n",
    "all_test_data = []\n",
    "all_test_labels = []\n",
    "for PIL_image, label in test_dataset:\n",
    "    # image = np.transpose(PIL_image, (2, 0, 1))\n",
    "    if label in label_list:\n",
    "        all_test_data.append(PIL_image)\n",
    "        all_test_labels.append(np.where(label == label_list)[0][0])\n",
    "\n",
    "all_train_data = np.array(all_train_data, dtype=Image.Image)\n",
    "all_test_data = np.array(all_test_data, dtype=Image.Image)\n",
    "all_train_labels = np.array(all_train_labels, dtype=np.long)\n",
    "all_test_labels = np.array(all_test_labels, dtype=np.long)\n",
    "\n",
    "all_train_data.shape, all_test_data.shape, \\\n",
    "all_train_labels.shape, all_test_labels.shape, \\\n",
    "np.unique(all_train_labels), np.unique(all_train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Divide data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "((4, 5000), (4, 1000))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = np.unique(all_train_labels).shape[0]\n",
    "classified_train_data = [all_train_data[all_train_labels == i] for i in range(n_classes)]\n",
    "classified_train_data = np.array(classified_train_data, dtype=Image.Image)\n",
    "classified_test_data = [all_test_data[all_test_labels == i] for i in range(n_classes)]\n",
    "classified_test_data = np.array(classified_test_data, dtype=Image.Image)\n",
    "\n",
    "n_clients = 4\n",
    "clients = ['Client-{}'.format(i) for i in range(n_clients)]\n",
    "seq_0 = [0, 1, 2, 3]\n",
    "seq_1 = [1, 2, 3, 0]\n",
    "seq_2 = [2, 3, 0, 1]\n",
    "\n",
    "classified_train_data.shape, classified_test_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client-0 (5400,) (5400,)\n",
      "Client-1 (5400,) (5400,)\n",
      "Client-2 (5400,) (5400,)\n",
      "Client-3 (5400,) (5400,)\n",
      "(4, 5400, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "client_data = []\n",
    "client_labels = []\n",
    "\n",
    "n_train = 1500\n",
    "n_test = 300\n",
    "\n",
    "for client_name, label_0, label_1, label_2 in zip(clients, seq_0, seq_1, seq_2):\n",
    "    train_data = [classified_train_data[label_0][:n_train],\n",
    "                  classified_train_data[label_1][n_train: n_train * 2],\n",
    "                  classified_train_data[label_2][n_train * 2: n_train * 3],\n",
    "                  ]\n",
    "    train_labels = [label_0] * n_train + [label_1] * n_train + [label_2] * n_train\n",
    "\n",
    "    test_data = [classified_test_data[label_0][:n_test],\n",
    "                 classified_test_data[label_1][n_test: n_test * 2],\n",
    "                 classified_test_data[label_2][ n_test * 2: n_test * 3],\n",
    "                 ]\n",
    "    test_labels = [label_0] * n_test + [label_1] * n_test + [label_2] * n_test\n",
    "\n",
    "    data = np.concatenate(train_data + test_data)\n",
    "    labels = np.array(train_labels + test_labels)\n",
    "\n",
    "    print(client_name, data.shape, labels.shape)\n",
    "\n",
    "    np.savez_compressed(os.path.join(root, '{}_dataset'.format(client_name)), data=data, labels=labels)\n",
    "\n",
    "    client_data.append([np.transpose(image, (2, 0, 1)) for image in data])\n",
    "    client_labels.append(labels)\n",
    "\n",
    "client_data = np.array(client_data, np.uint8)\n",
    "client_labels = np.array(client_labels, np.long)\n",
    "print(client_data.shape)\n",
    "\n",
    "np.savez_compressed(os.path.join(root, 'cifar10_dataset'),\n",
    "                    client_names=clients, data=client_data, labels=client_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 5400, 3, 32, 32)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.load(os.path.join(root, 'CIFAR10_dataset.npz'), allow_pickle=True)\n",
    "f['data'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([0, 1, 2]), array([1, 2, 3]), array([0, 2, 3]), array([0, 1, 3])]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.unique(i) for i in f['labels']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b1f1b1d5",
   "language": "python",
   "display_name": "PyCharm (fedHet)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}